{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python:3.9.13\n",
    "\n",
    "tensorflow:2.18.0\n",
    "\n",
    "torch:2.6.0\n",
    "\n",
    "----\n",
    "\n",
    "每局只取1个样本：慢  \n",
    "\n",
    "缓慢降温增加探索性：效果不好。奖励只在最后一步才出现，探索性破坏奖励信号？  \n",
    "\n",
    "更小卷积核：测试效果很差  \n",
    "\n",
    "q-learning：测试效果很差  \n",
    "\n",
    "sarsa：测试效果很差  \n",
    "\n",
    "补充人工信息：效果提升\n",
    "\n",
    "增加层数：加了两层，大部分时候表现优于aug，但是有交叉。\n",
    "\n",
    "降低 learning rate: 从 1e-3 降低到 1e-4, 表现提升。\n",
    "\n",
    "----\n",
    "\n",
    "目前aug(base4基础上，输入数据增加了人工信息) 略优于 base4(补上了base2遗漏的batch normalization 和 dropout)\n",
    "\n",
    "bigger(增加了两层) 略优于 aug\n",
    "\n",
    "出牌信息里去掉带牌？可能意义不大\n",
    "\n",
    "为什么训练过程中表现有起伏呢？降低 learning rate？增加每个轮次的局数？DQN？\n",
    "\n",
    "如果DQN的话，要怎么做呢？DQN使用 experience buffer 是为了降低样本的相关性。在斗地主中，如果我一次收集很多局的样本，然后把样本打乱，喂给模型，这样就达到了降低样本相关性的目的吧。在这种情况下，policy network 本身就不是每一步都更新的。还有必要区分 policy network 和 target network 吗？\n",
    "\n",
    "按照DQN的逻辑，我是不是可以把同一批样本反复随机分割成batch喂给模型？可以加快训练速度吗？\n",
    "\n",
    "之前 q-learning 的效果太差了，完全没信心\n",
    "\n",
    "----\n",
    "\n",
    "trainer输出的loss意义有限。如果发牌高度偏向于地主或农民，那么预测就更准，loss就会更小。一轮只有8局，发牌的影响很大。\n",
    "\n",
    "----\n",
    "\n",
    "感觉 DouZero 所谓 Deep Monte-Carlo 跟我的逻辑是一样的。打牌，生成一整局游戏的样本，用最终的输赢作为预测目标，训练状态动作价值模型。多线程不熟悉代码不怎么看得懂，似乎一次生成50局游戏，然后 batch size 32\n",
    "\n",
    "----\n",
    "因为电脑是8核，之前都是每8局游戏更新模型。地主农民分三个模型之后，表现下降。可能是因为每个模型的样本数量只有之前的1/3。相应地改成每24局游戏更新一次，似乎表现提升，但是训练速度当然慢了很多。\n",
    "\n",
    "一个问题，把收集到的样本打乱，32个样本一个batch，不满32个的也当成一个batch，是不是有问题？不满32个的应该怎么处理。假如某组只有1个样本，是不是不太好？\n",
    "\n",
    "loss 修正: loss_factor = (len(xs_batch) / batch_size) ** 0.5  似无优势，可能训练过程略微平稳一些\n",
    "\n",
    "----\n",
    "\n",
    "怎么把douzero模型下载并跑起来……\n",
    "\n",
    "----\n",
    "\n",
    "tensorflow 模型 1696257 参数，运行速度 13ms，torch 模型 1457665 参数，运行速度 4ms。另外的我的模型需要的训练数据，组装速度也较慢，主要是组装额外数据(aug加入)消耗了额外的时间。\n",
    "\n",
    "----\n",
    "\n",
    "torch 比 tensorflow 快很多。发现用 torch 时，如果 batch size 为 1 会报错。所以 bn 是在一个 batch 内做 normalization？感觉不对劲。  \n",
    "BatchNorm2D: batch 内所有样本同一个 channel 所有数据做 normalization, scaled(x[:, idx_channel, :, :])  \n",
    "LayerNorm: batch 内每个样本单独做 normalization, scaled(x[idx_sample, :, :, :])  \n",
    "算了，改用 LayerNorm 吧  \n",
    "发现 LayerNorm 更平稳。为什么？ 直觉上似乎 batch normalization 更合理？因为有少数 batch size 不是固定的32？ batch size 太小？\n",
    "\n",
    "----\n",
    "\n",
    "似乎遇到内存泄露，跑了一晚上，报错停止了。  \n",
    "使用 with mp.Pool() as pool, 内存稳定，但速度慢很多  \n",
    "使用 del, 无效  \n",
    "使用 del 和 gc.collect(), 无效，速度慢  \n",
    "将就一下，仍旧使用 pool = mp.Poo() 以及每200轮关闭和重建创建 pool\n",
    "\n",
    "----\n",
    "\n",
    "公司个人办公电脑效率测试：trainer_torch_ln, 两分钟\n",
    "cpu| rounds\n",
    "----|----\n",
    "1| 59\n",
    "2| 79\n",
    "3| 90\n",
    "4| 94\n",
    "5| 98\n",
    "6| 102\n",
    "\n",
    "公司linux服务器效率测试：trainer_torch_ln, 两分钟\n",
    "cpu|rounds\n",
    "----|----\n",
    "1| 50\n",
    "2| 58\n",
    "3| 38\n",
    "4| 13\n",
    "6| 4\n",
    "\n",
    "同样的代码，在我的公司电脑上运行的速度是在公司服务器/阿里云服务器上的20多倍。为什么？linux的问题？从资源占用来看，服务器上的cpu也是一直在工作的。  \n",
    "找到原因了。模型计算时默认使用多核，各进程的模型互相抢CPU。不知道为什么这个问题在个人PC上没那么严重，windows和linux的差异？  \n",
    "torch.set_num_threads 设置使用模型使用的线程数。在linux服务器上设置12进程，子进程 torch.set_num_threads(1) 之后，两分钟跑了80轮  \n",
    "本地PC采用8进程和torch.set_num_threads(1)之后，运行速度似有些微提升。\n",
    "\n",
    "-----\n",
    "使用 python multiprocessing 多进程遇到的问题：  \n",
    "内存占用不断增加：使用 with mp.Pool() as pool 可以避免这个问题，但是会降低程序运行速度。改成在循环中每隔若干轮关闭并重建pool。  \n",
    "使用 Process(target, args)，不一定使用多核。不知道如何指定使用几个进程。即使使用多核，使用队列传递数据，程序运行速度相比 pool.map 也不见优势。  \n",
    "使用多进程，运行速度没有线性增加。  \n",
    "使用6核，设定每个 selfplay 进行一局游戏，执行24次，或者设定每个selfplay 进行4局游戏，执行6次，运行效率没区别。但把总执行次数改成48局，前一种会稍慢。说明复制参数或收集返回结果确实有计算成本，只是在本电脑本问题上不是很显著。  \n",
    "\n",
    "----\n",
    "Dropout: 同样的输入，在 train 模式下，输出会不一样。但是如果输出的方差很大，这会不会是个问题？  \n",
    "刚才是用随机生成的数据测试。重新用实际的牌局数据测试，方差不大。\n",
    "\n",
    "----\n",
    "不合理出牌：  \n",
    "bot_torch_ln: 316300  \n",
    "\n",
    "```\n",
    "0.99337137 6 A A A\n",
    "0.9860233 6 6 A A A\n",
    "0.985545 3 A A A\n",
    "0.9849531 3\n",
    "0.9831738 A A A\n",
    "21 :  地主 : 6 A A A | 3 6 大王\n",
    "22 : 农民1 :  | 4 5 7 7 J Q Q K K 2\n",
    "23 : 农民2 :  | 3 3 4 4 4 5 5 10 2 2\n",
    "```\n",
    "\n",
    "----\n",
    "\n",
    "每100轮(24局1轮)存1次模型，与douzero比较，地主农民各1000局，统计45万轮之后各模型的胜利局数。分开看做地主和做农民时的胜利局数，统计的方差和基于胜率估算的方差相差不大。但是把做地主和做农民胜利的局数加起来看，统计的方差和基于胜率估算的方差相差很大。地主胜率和农民胜率相关系数 -0.6。这种情况给人什么感觉呢？好像模型实力已经不怎么提升了，只是在左右互搏的过程中限入了某种循环状态。类似 地主策略 A > 农民策略 A > 地主策略B > 农民策略 B > 地主策略 A\n",
    "\n",
    "使用最近200轮的模型池生成样本能避免这种情况吗？目前从30万轮起，跑了7万轮，地主胜率和农民胜率相关系数同样 -0.6。继续跑看看。\n",
    "\n",
    "上面的猜测好像不对。测试的时候，每组发牌打两局，一局当地主，一局当农民。如果测试某一轮的模型时，发的牌整体偏向地主，地主胜率就高，农民胜率就低\n",
    "\n",
    "----\n",
    "\n",
    "从前200个模型中随机抽取模型对战生成样本，避免可能的策略过拟合：看不出来效果。\n",
    "\n",
    "----\n",
    "\n",
    "根据模型打牌，生成一个局面信息的序列。然后在序列的每一步，选择其他（最多4手）评分高的出牌选项，接下来再按模型打牌，生成序列。  \n",
    "如此得到一个局面信息的树，每一层有若干个子结点，对应当前局面下的不同出牌，但只有一个子结点（最高胜率的出牌）有分支，其他的都是一条线直到叶结点。  \n",
    "即先按模型生成主干，然后在主干上的每一步分出分支，每个分支不再有新的分支，而是按模型一路走到底。  \n",
    "希望具有的优点：1, 一手牌提供更多的训练数据。2, 同一个局面下的不同出牌的奖励对比能提供更有效的训练信号。  \n",
    "还在训练中……  \n",
    "试验几种设置：一轮6局，batch size=32 | 一轮24局，batch size=32 | 一轮24局，batch size=128  \n",
    "一轮24局，batch size=128 较好  \n",
    "训练似乎较慢。每局游戏生成的样本数量大大增加（50多倍），每一轮的耗时也大大增加。虽然样本多，但对应的初始发牌少，训练速度慢可能与此有关。继续训练希望表现能更好。\n",
    "\n",
    "表现似乎有所提升，对douzero胜率大概提升了0.5%\n",
    "\n",
    "----\n",
    "不作弊的模型  \n",
    "128局一轮优于24局一轮  \n",
    "增加自己手牌的顺子、连对、飞机信息，表现较大提升  \n",
    "使用 lstm_out 和 h_n 作为下一步的输入，表现无差异"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "import rules\n",
    "import arena as arn\n",
    "import bot_torch_ln\n",
    "import bot_aug\n",
    "CARDS = rules.CARDS\n",
    "ARENA = arn.ARENA\n",
    "bot_rd = arn.bot_rd\n",
    "bot_me = arn.bot_me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bot_douzero' from 'd:\\\\py\\\\ddz_2025_2\\\\bot_douzero.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bot_douzero\n",
    "import importlib\n",
    "importlib.reload(bot_douzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft(N, bot1_f, bot2_f):\n",
    "    s1, s2 = 0, 0\n",
    "    for i in range(N):\n",
    "        cards = rules.CARDS.copy()\n",
    "        np.random.shuffle(cards)\n",
    "        \n",
    "        arena = ARENA(verbos=0, cards=cards.copy())\n",
    "        arena.registerbot([bot1_f(), bot2_f(), bot2_f()])\n",
    "        arena.wholegame()\n",
    "        s1 += arena.winner == 0\n",
    "\n",
    "        arena = ARENA(verbos=0, cards=cards.copy())\n",
    "        arena.registerbot([bot2_f(), bot1_f(), bot1_f()])\n",
    "        arena.wholegame()\n",
    "        s2 += arena.winner == 0\n",
    "\n",
    "    return s1, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models & bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import randbot_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#451500: 2089, 1542 | 5547/10000\n",
    "#499000: 2078, 1594 | 5484/10000\n",
    "#400900: 2135, 1656 | 5479/10000\n",
    "#473700: 2129, 1610 | 5519/10000\n",
    "#520500: 2157, 1618 | 5539/10000\n",
    "#672200: 2135, 1533 | 5602/10000\n",
    "#701000: 2184, 1556 | 5628/10000\n",
    "#745700：2112, 1521 | 5591/10000\n",
    "cp = torch.load(\"model_torch_ln/cp701000.pt\")\n",
    "models = []\n",
    "for pos in range(3):\n",
    "    model = bot_torch_ln.Model()\n",
    "    model.eval()\n",
    "    model.load_state_dict(cp[\"models_state_dict\"][pos])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7489: 2143, 1644 | 5499/10000\n",
    "# 7712: 2126, 1682 | 5440/10000\n",
    "#12762: 2127, 1509 | 5618/10000\n",
    "#12782: 2106, 1478 | 5628/10000\n",
    "#13339: 2163, 1494 | 5669/10000\n",
    "#14315: 2188, 1509 | 5679/10000  vs model_torch_ln/cp701000: 1677, 1630 / 5000\n",
    "#14384: 2026, 1439 | 5587/10000\n",
    "#14427: 2036, 1507 | 5529/10000\n",
    "#14671: 2088, 1481 | 5607/10000\n",
    "#15783: 2093, 1436 | 5657/10000\n",
    "cp_tree = torch.load(\"model_tree2/cp14315.pt\")\n",
    "models_tree = []\n",
    "for pos in range(3):\n",
    "    model = bot_torch_ln.Model()\n",
    "    model.eval()\n",
    "    model.load_state_dict(cp_tree[\"models_state_dict\"][pos])\n",
    "    models_tree.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bot_torch_ln_f(verbos=0):\n",
    "    return bot_torch_ln.BOT(models, verbos=verbos)\n",
    "\n",
    "def bot_tree_f(verbos=0):\n",
    "    return bot_torch_ln.BOT(models_tree, verbos=verbos)\n",
    "\n",
    "def bot_rand_f(verbos=0, sample=10):\n",
    "    return randbot_three.BOT([bot_torch_ln_f(0), bot_torch_ln_f(0), bot_torch_ln_f(0)], verbos=verbos, sample=sample)\n",
    "\n",
    "model_aug = k.models.load_model(\"e:/ddz_2025_2_model/model_aug/m488750.keras\")\n",
    "def bot_aug_f(verbos=0):\n",
    "    return bot_aug.BOT(model_aug, verbos)\n",
    "\n",
    "def bot_rd_f():\n",
    "    return bot_rd\n",
    "\n",
    "def bot_douzero_f(verbos=0):\n",
    "    return bot_douzero.BOT(verbos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677, 1630)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# ft(N, bot_torch_ln_f, bot_douzero_f)  ##623\n",
    "# ft(N, bot_douzero_f, bot_douzero_f) ##66\n",
    "ft(N, bot_tree_f, bot_torch_ln_f)\n",
    "# ft(N, bot_tree_f, bot_douzero_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037720356 3 3\n",
      "0.03566752 4 4\n",
      "0.019491475 3\n",
      "0.018694827 8\n",
      "0.01810125 6\n",
      " 0 :  地主 : 3 3 | 4 4 5 6 6 7 8 8 9 10 10 Q Q K A 2 小王 大王\n",
      "0.9358061 7 7\n",
      "0.9322855 5 5\n",
      "0.93197274 \n",
      "0.90656066 J J\n",
      "0.89731216 K K\n",
      " 1 : 农民1 : 7 7 | 3 3 5 5 8 9 10 J J Q K K A 2 2\n",
      "0.9014698 \n",
      "0.8112476 A A\n",
      "0.79149675 9 9\n",
      "0.7345604 J J\n",
      " 2 : 农民2 :  | 4 4 5 6 6 7 8 9 9 10 J J Q K A A 2\n",
      "0.01725153 8 8\n",
      "0.016592976 10 10\n",
      "0.014270077 Q Q\n",
      "0.0063977353 \n",
      "0.00023042299 小王 大王\n",
      " 3 :  地主 : 8 8 | 4 4 5 6 6 7 9 10 10 Q Q K A 2 小王 大王\n",
      "0.98421067 \n",
      "0.9826357 K K\n",
      "0.9805629 J J\n",
      "0.9623565 2 2\n",
      " 4 : 农民1 :  | 3 3 5 5 8 9 10 J J Q K K A 2 2\n",
      "0.9318038 9 9\n",
      "0.9243262 \n",
      "0.92123544 J J\n",
      "0.9170981 A A\n",
      " 5 : 农民2 : 9 9 | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.040947463 10 10\n",
      "0.03745124 Q Q\n",
      "0.011923501 \n",
      "0.00020095741 小王 大王\n",
      " 6 :  地主 : 10 10 | 4 4 5 6 6 7 9 Q Q K A 2 小王 大王\n",
      "0.953721 K K\n",
      "0.9505284 \n",
      "0.9236219 J J\n",
      "0.90811497 2 2\n",
      " 7 : 农民1 : K K | 3 3 5 5 8 9 10 J J Q A 2 2\n",
      "0.8804683 \n",
      "0.7927585 A A\n",
      " 8 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.010611471 \n",
      "0.00022327603 小王 大王\n",
      " 9 :  地主 :  | 4 4 5 6 6 7 9 Q Q K A 2 小王 大王\n",
      "0.969662 8 9 10 J Q\n",
      "0.94118315 5 5\n",
      "0.9297405 3 3\n",
      "0.9142401 9\n",
      "0.91392976 8\n",
      "10 : 农民1 : 8 9 10 J Q | 3 3 5 5 J A 2 2\n",
      "0.880679 \n",
      "0.5546248 10 J Q K A\n",
      "11 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.010229021 \n",
      "0.00020607126 小王 大王\n",
      "12 :  地主 :  | 4 4 5 6 6 7 9 Q Q K A 2 小王 大王\n",
      "0.9693685 3 3\n",
      "0.9692772 5 5\n",
      "0.92871094 J\n",
      "0.9230444 3\n",
      "0.9211609 2\n",
      "13 : 农民1 : 3 3 | 5 5 J A 2 2\n",
      "0.9213849 \n",
      "0.86268336 J J\n",
      "0.82812715 6 6\n",
      "0.8171849 4 4\n",
      "0.79119915 A A\n",
      "14 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.031180585 4 4\n",
      "0.023022253 6 6\n",
      "0.010019377 Q Q\n",
      "0.0012725543 \n",
      "0.0001322345 小王 大王\n",
      "15 :  地主 : 4 4 | 5 6 6 7 9 Q Q K A 2 小王 大王\n",
      "0.9876869 5 5\n",
      "0.9285315 2 2\n",
      "0.9273936 \n",
      "16 : 农民1 : 5 5 | J A 2 2\n",
      "0.9768802 \n",
      "0.968055 J J\n",
      "0.9568356 6 6\n",
      "0.94690853 A A\n",
      "17 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.01008374 6 6\n",
      "0.008199822 Q Q\n",
      "0.0006029934 \n",
      "0.000117844786 小王 大王\n",
      "18 :  地主 : 6 6 | 5 7 9 Q Q K A 2 小王 大王\n",
      "0.9929528 2 2\n",
      "0.95699316 \n",
      "19 : 农民1 : 2 2 | J A\n",
      "0.9952676 \n",
      "20 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.00058263395 小王 大王\n",
      "0.00022762537 \n",
      "21 :  地主 : 小王 大王 | 5 7 9 Q Q K A 2\n",
      "0.9978779 \n",
      "22 : 农民1 :  | J A\n",
      "0.9968156 \n",
      "23 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.00038426663 Q Q\n",
      "0.00031959824 7\n",
      "0.0003078367 5\n",
      "0.0001889617 9\n",
      "0.00018748628 A\n",
      "24 :  地主 : Q Q | 5 7 9 K A 2\n",
      "0.99930394 \n",
      "25 : 农民1 :  | J A\n",
      "0.9977789 \n",
      "0.9972845 A A\n",
      "26 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "0.00023863203 7\n",
      "0.00021780447 5\n",
      "0.0002120895 A\n",
      "0.00018209589 9\n",
      "0.00016781413 K\n",
      "27 :  地主 : 7 | 5 9 K A 2\n",
      "0.99972665 J\n",
      "0.99920356 A\n",
      "0.99171793 \n",
      "28 : 农民1 : J | A\n",
      "0.99941844 \n",
      "0.99932617 Q\n",
      "0.99907535 K\n",
      "0.9984611 A\n",
      "0.9955038 2\n",
      "29 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "8.06164e-05 A\n",
      "6.479727e-05 K\n",
      "5.655507e-05 2\n",
      "1.8500283e-05 \n",
      "30 :  地主 : A | 5 9 K 2\n",
      "0.9996729 \n",
      "31 : 农民1 :  | A\n",
      "0.9996174 \n",
      "0.99874115 2\n",
      "32 : 农民2 :  | 4 4 5 6 6 7 8 10 J J Q K A A 2\n",
      "5.8411348e-05 K\n",
      "5.4179825e-05 2\n",
      "4.6455345e-05 9\n",
      "3.624185e-05 5\n",
      "33 :  地主 : K | 5 9 2\n",
      "0.9999785 A\n",
      "0.99961007 \n",
      "34 : 农民1 : A | \n"
     ]
    }
   ],
   "source": [
    "arena = arn.ARENA(1, True)\n",
    "# arena.registerbot([bot_torch_ln_f(1), bot_douzero_f(1), bot_douzero_f(1)])\n",
    "arena.registerbot([bot_tree_f(1), bot_tree_f(1), bot_tree_f(1)])\n",
    "arena.wholegame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同样发牌交换地主农民"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    cards = CARDS.copy()\n",
    "\n",
    "    np.random.shuffle(cards)\n",
    "    arena = ARENA(cards=cards.copy())\n",
    "    arena.registerbot([bot_tree_f(), bot_douzero_f(), bot_douzero_f()])\n",
    "    arena.wholegame()\n",
    "    w1 = arena.winner\n",
    "    \n",
    "    arena = ARENA(cards=cards.copy())\n",
    "    arena.registerbot([bot_douzero_f(), bot_tree_f(), bot_tree_f()])\n",
    "    arena.wholegame()\n",
    "    w2 = arena.winner\n",
    "    \n",
    "    if (w1==0) != (w2==0):\n",
    "        arena = ARENA(cards=cards)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044815898 3 4 5 6 7\n",
      "0.012974928 3 4 5 6 7 8 9\n",
      "0.012666023 8 8 8 2\n",
      "0.011489981 8 8 8 9\n",
      "0.010719384 K K\n",
      " 0 :  地主 : 3 4 5 6 7 | 8 8 8 9 10 10 J J Q Q Q K K A 2\n",
      "0.4301774 10 J Q K A\n",
      "0.31327137 9 10 J Q K\n",
      "0.30184177 \n",
      " 1 : 农民1 : 10 J Q K A | 3 4 5 5 7 7 7 9 9 2 2 大王\n",
      " 2 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "0.025917644 \n",
      " 3 :  地主 :  | 8 8 8 9 10 10 J J Q Q Q K K A 2\n",
      "0.47141758 9 9\n",
      "0.46067223 5 5\n",
      "0.4533853 3 7 7 7\n",
      "0.4356561 3\n",
      "0.42090124 5 5 7 7 7\n",
      " 4 : 农民1 : 9 9 | 3 4 5 5 7 7 7 2 2 大王\n",
      "0.6435713 \n",
      "0.2126899 A A\n",
      " 5 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "0.030402439 10 10\n",
      "0.014142957 J J\n",
      "0.011686614 \n",
      "0.008780964 K K\n",
      "0.0015863057 Q Q\n",
      " 6 :  地主 : 10 10 | 8 8 8 9 J J Q Q Q K K A 2\n",
      "0.4556514 \n",
      "0.3229889 2 2\n",
      " 7 : 农民1 :  | 3 4 5 5 7 7 7 2 2 大王\n",
      "0.34693265 A A\n",
      "0.32949412 \n",
      " 8 : 农民2 : A A | 3 3 4 4 5 6 6 6 8 9 10 J K 2 小王\n",
      "0.06705099 \n",
      " 9 :  地主 :  | 8 8 8 9 J J Q Q Q K K A 2\n",
      "0.36528406 \n",
      "0.14076768 2 2\n",
      "10 : 农民1 :  | 3 4 5 5 7 7 7 2 2 大王\n",
      "0.51167566 3 3\n",
      "0.5108242 4 4\n",
      "0.50972074 6 6\n",
      "0.40327597 4 4 6 6 6\n",
      "0.39921516 3 3 6 6 6\n",
      "11 : 农民2 : 3 3 | 4 4 5 6 6 6 8 9 10 J K 2 小王\n",
      "0.06937712 \n",
      "0.061109643 J J\n",
      "0.056810785 K K\n",
      "0.008849266 8 8\n",
      "0.0025345483 Q Q\n",
      "12 :  地主 :  | 8 8 8 9 J J Q Q Q K K A 2\n",
      "0.62570053 5 5\n",
      "0.27846056 \n",
      "0.09090563 2 2\n",
      "0.014273547 7 7\n",
      "13 : 农民1 : 5 5 | 3 4 7 7 7 2 2 大王\n",
      "0.7783607 \n",
      "0.7562921 6 6\n",
      "14 : 农民2 :  | 4 4 5 6 6 6 8 9 10 J K 2 小王\n",
      "0.012166863 J J\n",
      "0.011280589 K K\n",
      "0.005884301 \n",
      "0.0021812308 8 8\n",
      "0.0005322894 Q Q\n",
      "15 :  地主 : J J | 8 8 8 9 Q Q Q K K A 2\n",
      "0.6753521 2 2\n",
      "0.63431704 \n",
      "16 : 农民1 : 2 2 | 3 4 7 7 7 大王\n",
      "17 : 农民2 :  | 4 4 5 6 6 6 8 9 10 J K 2 小王\n",
      "0.06708678 \n",
      "18 :  地主 :  | 8 8 8 9 Q Q Q K K A 2\n",
      "0.80021095 4\n",
      "0.7491412 3\n",
      "0.6210469 4 7 7 7\n",
      "0.56179833 3 7 7 7\n",
      "0.15560183 7 7 7\n",
      "19 : 农民1 : 4 | 3 7 7 7 大王\n",
      "0.6353038 9\n",
      "0.6342069 J\n",
      "0.62588406 10\n",
      "0.6230834 5\n",
      "0.6169322 6\n",
      "20 : 农民2 : 9 | 4 4 5 6 6 6 8 10 J K 2 小王\n",
      "0.16001624 2\n",
      "0.1501955 A\n",
      "0.024656786 K\n",
      "0.011823178 Q\n",
      "0.010681471 \n",
      "21 :  地主 : 2 | 8 8 8 9 Q Q Q K K A\n",
      "0.87978077 大王\n",
      "0.6140402 \n",
      "22 : 农民1 : 大王 | 3 7 7 7\n",
      "23 : 农民2 :  | 4 4 5 6 6 6 8 10 J K 2 小王\n",
      "0.044782534 \n",
      "24 :  地主 :  | 8 8 8 9 Q Q Q K K A\n",
      "1.0163493 3 7 7 7\n",
      "-0.011982761 7 7 7\n",
      "-0.100857 3\n",
      "-0.21648681 7\n",
      "-0.29671523 7 7\n",
      "25 : 农民1 : 3 7 7 7 | \n"
     ]
    }
   ],
   "source": [
    "arena = ARENA(1, cards=cards.copy())\n",
    "arena.registerbot([bot_tree_f(1), bot_douzero_f(1), bot_douzero_f(1)])\n",
    "arena.wholegame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49775583 3 4 5 6 7\n",
      "-0.6626981 8 8\n",
      "-0.6694203 3 4 5 6 7 8\n",
      "-0.74220794 8\n",
      "-0.79250985 3\n",
      " 0 :  地主 : 3 4 5 6 7 | 8 8 8 9 10 10 J J Q Q Q K K A 2\n",
      "0.982307 9 10 J Q K\n",
      "0.9822033 10 J Q K A\n",
      "0.92688024 \n",
      " 1 : 农民1 : 9 10 J Q K | 3 4 5 5 7 7 7 9 A 2 2 大王\n",
      "0.9884756 \n",
      " 2 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "-0.30485788 10 J Q K A\n",
      "-0.838125 \n",
      " 3 :  地主 : 10 J Q K A | 8 8 8 9 10 J Q Q K 2\n",
      "0.89351285 \n",
      " 4 : 农民1 :  | 3 4 5 5 7 7 7 9 A 2 2 大王\n",
      "0.87796545 \n",
      " 5 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "0.11485767 9 10 J Q K\n",
      "-0.088388056 8 8 8 Q\n",
      "-0.3348835 8 8 8 2\n",
      "-0.5829635 Q\n",
      "-0.6525965 8 8 8\n",
      " 6 :  地主 : 9 10 J Q K | 8 8 8 Q 2\n",
      "0.12513119 \n",
      " 7 : 农民1 :  | 3 4 5 5 7 7 7 9 A 2 2 大王\n",
      "0.13149017 \n",
      " 8 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "0.1280784 8 8 8 Q\n",
      "-0.12754178 8 8 8 2\n",
      "-0.63166255 8 8 8\n",
      "-0.79782104 2\n",
      "-0.802111 Q\n",
      " 9 :  地主 : 8 8 8 Q | 2\n",
      "0.052092493 \n",
      "10 : 农民1 :  | 3 4 5 5 7 7 7 9 A 2 2 大王\n",
      "3.373623e-05 \n",
      "11 : 农民2 :  | 3 3 4 4 5 6 6 6 8 9 10 J K A A 2 小王\n",
      "12 :  地主 : 2 | \n"
     ]
    }
   ],
   "source": [
    "arena = ARENA(1, cards=cards.copy())\n",
    "arena.registerbot([bot_douzero_f(1), bot_tree_f(1), bot_tree_f(1)])\n",
    "arena.wholegame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试不同轮次的地主和农民"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "cp = torch.load(\"model_torch_ln/cp520500.pt\")\n",
    "model = bot_torch_ln.Model()\n",
    "model.eval()\n",
    "model.load_state_dict(cp[\"models_state_dict\"][0])\n",
    "models.append(model)\n",
    "\n",
    "cp = torch.load(\"model_torch_ln/cp451500.pt\")\n",
    "\n",
    "model = bot_torch_ln.Model()\n",
    "model.eval()\n",
    "model.load_state_dict(cp[\"models_state_dict\"][1])\n",
    "models.append(model)\n",
    "\n",
    "model = bot_torch_ln.Model()\n",
    "model.eval()\n",
    "model.load_state_dict(cp[\"models_state_dict\"][2])\n",
    "models.append(model)\n",
    "\n",
    "def bot_torch_ln_f(verbos=0):\n",
    "    return bot_torch_ln.BOT(models, verbos=verbos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2166, 1620)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# ft(N, bot_three_f, bot_three_f)  ##623\n",
    "# ft(N, bot_douzero_f, bot_douzero_f) ##66\n",
    "ft(N, bot_torch_ln_f, bot_douzero_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据发牌构建arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def repl(matched):\n",
    "    d = {\"11\": \"J\", \"12\": \"Q\", \"13\": \"K\", \"14\": \"A\", \"15\": \"2\", \"16\": \"小王\", \"17\": \"大王\"}\n",
    "    return d[matched[0]]\n",
    "\n",
    "def arenabyscratch(l):\n",
    "    cards = [rules.str2vec(re.sub(r'1[1-7]', repl, v)) for v in re.split(\",\", l)]\n",
    "        \n",
    "    arena=object.__new__(arn.ARENA)\n",
    "    arena.verbos = 1\n",
    "    arena.init = np.array(cards, int)\n",
    "    arena.remain = arena.init.copy()\n",
    "    arena.lastplay = np.zeros((3, 15), int)\n",
    "    arena.pos = 0\n",
    "    arena.b1 = 2\n",
    "    arena.b2 = 1\n",
    "    arena.round = 0\n",
    "    arena.bot = []\n",
    "    arena.gameover = False\n",
    "    arena.winner = None\n",
    "    arena.getdata()\n",
    "    arena.RECORD = True\n",
    "    arena.records = []\n",
    "    if arena.RECORD:\n",
    "        arena.records.append(arena.copy())\n",
    "    return arena\n",
    "\n",
    "arena = arenabyscratch(\"3 4 4 4 4 5 5 7 8 9 9 9 10 11 12 13 13 14 14 17, 3 5 5 6 6 6 7 7 7 8 9 10 11 12 13 13 15, 3 3 6 8 8 10 10 11 11 12 12 14 14 15 15 15 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 草稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arena.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arena.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 2, 1, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena.records[-2].remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena.history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
